#!/bin/bash
#SBATCH --nodes=1                           # node count
#SBATCH --ntasks=1                          # total number of tasks across all nodes
#SBATCH --cpus-per-task=1                   # cpu-cores per task (>1 if multi-threaded tasks), 4 is default
#SBATCH --gpus=1                            # number of gpus per node
#SBATCH --partition=gpu_h100   	            # partition
#SBATCH --time=00:10:00                     # total run time limit (HH:MM:SS)
#SBATCH --output=logs/%x/%j_%x.log          # output file

############################################################
cd ~/dl4nlp-project  # sanity check, for snellius
source .venv/bin/activate
python -c "import torch; print('Torch version:', torch.__version__); print('CUDA check:', torch.cuda.is_available())"  # check torch version
############################################################

# models to use:
# Qwen/Qwen2-1.5B-Instruct
# or a model generated by finetune.job, e.g.
# checkpoints/domain=fr_en=target/finetune_15204259

# usage:
# sbatch jobs/eval.job <model> <source_lang> <target_lang> <annotation_lang> <data_dir>

python src/eval.py \
  --model ${1} \
  --data_dir ${5} \
  --split eval \
  --source_lang ${2} \
  --target_lang ${3} \
  --batch_size 16 \
  --dtype float16 \
  --annotations_jsonl src/annotate/annotations_en_${4}.jsonl \
